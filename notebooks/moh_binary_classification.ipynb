{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d1aa2d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "797213d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df = pd.read_excel(\"../Data/responses_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93910207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(df):\n",
    "    df = df.copy().rename(columns={\"description\":'question_description'})\n",
    "    df  = df[['question_description', 'answer_category_num']]\n",
    "    df.drop_duplicates(subset='question_description', inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # checking how many comments have different votes\n",
    "    for i, row in df.iterrows():\n",
    "\n",
    "        comment = row.question_description\n",
    "\n",
    "        # getting the dataframe for that comment\n",
    "        temp_df = df[df.question_description == comment]\n",
    "\n",
    "        # how many unique answers that comment has\n",
    "        n_ = temp_df.answer_category_num.nunique()\n",
    "\n",
    "        # changing the answer_category_num to the most frequent one\n",
    "        if n_ >= 2:\n",
    "            most_voted_label = temp_df.answer_category_num.value_counts().index[0]\n",
    "            df.at[i, 'answer_category_num'] = most_voted_label\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fad1fa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df_clean = prepare_df(responses_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8391a0",
   "metadata": {},
   "source": [
    "## `turning the problem into binary classification`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0c3fb8",
   "metadata": {},
   "source": [
    "### hate / not hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee549f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ee3e7559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definitions\n",
    "LogReg_model = LogisticRegression()\n",
    "RandomForestClassifier_model = RandomForestClassifier(max_depth=3, random_state=0)\n",
    "\n",
    "MultinomialNB_model = MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)\n",
    "SGDClassifier_model = SGDClassifier(class_weight='balanced', penalty='l1')\n",
    "KNeighborsClassifier_model = KNeighborsClassifier(n_neighbors=3)\n",
    "DecisionTreeClassifier_model = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "models = [LogReg_model, RandomForestClassifier_model, DecisionTreeClassifier_model,\n",
    "          SGDClassifier_model,   \n",
    "          KNeighborsClassifier_model,  MultinomialNB_model]\n",
    "model_names = ['LogisticRegression', 'RandomForestClassifier', 'DecisionTreeClassifier',\n",
    "               'SGDClassifier', 'KNeighborsClassifier', 'MultinomialNB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "994d3e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_classes(df, class_chosen=\"hate\"):\n",
    "    responses_df_binary = df.copy()\n",
    "    \n",
    "    \n",
    "    data_classes = responses_df_binary[\"answer_category_num\"].unique()\n",
    "    if class_chosen not in data_classes:\n",
    "        mapping_classes = {'Religious affiliation': \"hate\", \n",
    "                           'Violent': \"hate\", \n",
    "                           'Racist': \"hate\", \n",
    "                           'Mockery': \"hate\",\n",
    "                           'Sexual harrasment': \"hate\", \n",
    "                           'Normal': \"not hate\"}\n",
    "    else:\n",
    "        mapping_classes = {}\n",
    "        for class_i in data_classes:\n",
    "            if class_i == class_chosen:\n",
    "                mapping_classes[class_i] = \"{}\".format(class_chosen)\n",
    "            else:\n",
    "                mapping_classes[class_i] = \"not {}\".format(class_chosen)\n",
    "    \n",
    "    responses_df_binary = responses_df_binary.replace({\"answer_category_num\": mapping_classes})\n",
    "    return responses_df_binary\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "165a5a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(df, model_names):\n",
    "    def train_models(X_tr, X_te, y_tr, y_te):\n",
    "        for i, model in enumerate(models):\n",
    "            print(f\"Model: {model_names[i]}\")\n",
    "            model.fit(X_tr, y_tr)\n",
    "            y_pred = model.predict(X_te)\n",
    "            print('val accuracy %s' % accuracy_score(y_te, y_pred))\n",
    "            print(classification_report(y_te, y_pred))  # for further evaluation\n",
    "            print()\n",
    "    \n",
    "    train_data, test_data = train_test_split(df, test_size=0.15, random_state=42)\n",
    "    tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 1))\n",
    "    tfidf_tr = tfidf_vectorizer.fit_transform(train_data['question_description'])\n",
    "    tfidf_val = tfidf_vectorizer.transform(test_data['question_description'])\n",
    "    \n",
    "    X_train, y_train = tfidf_tr, train_data['answer_category_num']\n",
    "    X_test, y_test = tfidf_val, test_data['answer_category_num']\n",
    "    \n",
    "    train_models(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29428603",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d5130877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_description</th>\n",
       "      <th>answer_category_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>وزير الخارجية اللبناني جبران باسيل قال في سلسل...</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>سورية بلد الحضارات تربطها بعلية او بحيوان</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>تقتلون وسام الحسن وتترحموعلية من أي أصناف المخ...</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>معك خبر انو بلدة قطر متل ما سميتا مساحتها اكبر...</td>\n",
       "      <td>not hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>للامانه قوت الموسم اللي طاف كان هوا بس متحمس ح...</td>\n",
       "      <td>not hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                question_description answer_category_num\n",
       "0  وزير الخارجية اللبناني جبران باسيل قال في سلسل...                hate\n",
       "1          سورية بلد الحضارات تربطها بعلية او بحيوان                hate\n",
       "2  تقتلون وسام الحسن وتترحموعلية من أي أصناف المخ...                hate\n",
       "3  معك خبر انو بلدة قطر متل ما سميتا مساحتها اكبر...            not hate\n",
       "4  للامانه قوت الموسم اللي طاف كان هوا بس متحمس ح...            not hate"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: LogisticRegression\n",
      "val accuracy 0.7219827586206896\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        hate       0.73      0.98      0.84       336\n",
      "    not hate       0.45      0.04      0.07       128\n",
      "\n",
      "    accuracy                           0.72       464\n",
      "   macro avg       0.59      0.51      0.45       464\n",
      "weighted avg       0.65      0.72      0.63       464\n",
      "\n",
      "\n",
      "Model: RandomForestClassifier\n",
      "val accuracy 0.7241379310344828\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        hate       0.72      1.00      0.84       336\n",
      "    not hate       0.00      0.00      0.00       128\n",
      "\n",
      "    accuracy                           0.72       464\n",
      "   macro avg       0.36      0.50      0.42       464\n",
      "weighted avg       0.52      0.72      0.61       464\n",
      "\n",
      "\n",
      "Model: DecisionTreeClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\modaj\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\modaj\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\modaj\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy 0.6530172413793104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        hate       0.74      0.81      0.77       336\n",
      "    not hate       0.33      0.25      0.28       128\n",
      "\n",
      "    accuracy                           0.65       464\n",
      "   macro avg       0.53      0.53      0.53       464\n",
      "weighted avg       0.63      0.65      0.64       464\n",
      "\n",
      "\n",
      "Model: SGDClassifier\n",
      "val accuracy 0.6508620689655172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        hate       0.75      0.79      0.77       336\n",
      "    not hate       0.35      0.30      0.32       128\n",
      "\n",
      "    accuracy                           0.65       464\n",
      "   macro avg       0.55      0.54      0.54       464\n",
      "weighted avg       0.64      0.65      0.64       464\n",
      "\n",
      "\n",
      "Model: KNeighborsClassifier\n",
      "val accuracy 0.6745689655172413\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        hate       0.77      0.78      0.78       336\n",
      "    not hate       0.41      0.39      0.40       128\n",
      "\n",
      "    accuracy                           0.67       464\n",
      "   macro avg       0.59      0.59      0.59       464\n",
      "weighted avg       0.67      0.67      0.67       464\n",
      "\n",
      "\n",
      "Model: MultinomialNB\n",
      "val accuracy 0.7112068965517241\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        hate       0.75      0.91      0.82       336\n",
      "    not hate       0.45      0.20      0.27       128\n",
      "\n",
      "    accuracy                           0.71       464\n",
      "   macro avg       0.60      0.55      0.55       464\n",
      "weighted avg       0.66      0.71      0.67       464\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# hate/not hate\n",
    "responses_df_binary_main = binarize_classes(responses_df_clean, class_chosen=\"hate\")\n",
    "display(responses_df_binary_main.head())\n",
    "print()\n",
    "\n",
    "train_and_evaluate(responses_df_binary_main, model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1b90d052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression\n",
      "val accuracy 0.8771551724137931\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "    Religious affiliation       0.00      0.00      0.00        57\n",
      "not Religious affiliation       0.88      1.00      0.93       407\n",
      "\n",
      "                 accuracy                           0.88       464\n",
      "                macro avg       0.44      0.50      0.47       464\n",
      "             weighted avg       0.77      0.88      0.82       464\n",
      "\n",
      "\n",
      "Model: RandomForestClassifier\n",
      "val accuracy 0.8771551724137931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\modaj\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\modaj\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\modaj\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\modaj\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\modaj\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\modaj\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           precision    recall  f1-score   support\n",
      "\n",
      "    Religious affiliation       0.00      0.00      0.00        57\n",
      "not Religious affiliation       0.88      1.00      0.93       407\n",
      "\n",
      "                 accuracy                           0.88       464\n",
      "                macro avg       0.44      0.50      0.47       464\n",
      "             weighted avg       0.77      0.88      0.82       464\n",
      "\n",
      "\n",
      "Model: DecisionTreeClassifier\n",
      "val accuracy 0.8318965517241379\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "    Religious affiliation       0.14      0.07      0.09        57\n",
      "not Religious affiliation       0.88      0.94      0.91       407\n",
      "\n",
      "                 accuracy                           0.83       464\n",
      "                macro avg       0.51      0.50      0.50       464\n",
      "             weighted avg       0.79      0.83      0.81       464\n",
      "\n",
      "\n",
      "Model: SGDClassifier\n",
      "val accuracy 0.8081896551724138\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "    Religious affiliation       0.20      0.19      0.20        57\n",
      "not Religious affiliation       0.89      0.89      0.89       407\n",
      "\n",
      "                 accuracy                           0.81       464\n",
      "                macro avg       0.55      0.54      0.54       464\n",
      "             weighted avg       0.80      0.81      0.81       464\n",
      "\n",
      "\n",
      "Model: KNeighborsClassifier\n",
      "val accuracy 0.8685344827586207\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "    Religious affiliation       0.30      0.05      0.09        57\n",
      "not Religious affiliation       0.88      0.98      0.93       407\n",
      "\n",
      "                 accuracy                           0.87       464\n",
      "                macro avg       0.59      0.52      0.51       464\n",
      "             weighted avg       0.81      0.87      0.83       464\n",
      "\n",
      "\n",
      "Model: MultinomialNB\n",
      "val accuracy 0.8728448275862069\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "    Religious affiliation       0.00      0.00      0.00        57\n",
      "not Religious affiliation       0.88      1.00      0.93       407\n",
      "\n",
      "                 accuracy                           0.87       464\n",
      "                macro avg       0.44      0.50      0.47       464\n",
      "             weighted avg       0.77      0.87      0.82       464\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Religious affiliation / not Religious affiliation\n",
    "responses_df_binary_main = binarize_classes(responses_df_clean, class_chosen=\"Religious affiliation\")\n",
    "train_and_evaluate(responses_df_binary_main, model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "67bdfc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression\n",
      "val accuracy 0.8168103448275862\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Violent       0.00      0.00      0.00        84\n",
      " not Violent       0.82      1.00      0.90       380\n",
      "\n",
      "    accuracy                           0.82       464\n",
      "   macro avg       0.41      0.50      0.45       464\n",
      "weighted avg       0.67      0.82      0.74       464\n",
      "\n",
      "\n",
      "Model: RandomForestClassifier\n",
      "val accuracy 0.8189655172413793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Violent       0.00      0.00      0.00        84\n",
      " not Violent       0.82      1.00      0.90       380\n",
      "\n",
      "    accuracy                           0.82       464\n",
      "   macro avg       0.41      0.50      0.45       464\n",
      "weighted avg       0.67      0.82      0.74       464\n",
      "\n",
      "\n",
      "Model: DecisionTreeClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\modaj\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\modaj\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\modaj\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy 0.7478448275862069\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Violent       0.20      0.13      0.16        84\n",
      " not Violent       0.82      0.88      0.85       380\n",
      "\n",
      "    accuracy                           0.75       464\n",
      "   macro avg       0.51      0.51      0.50       464\n",
      "weighted avg       0.71      0.75      0.73       464\n",
      "\n",
      "\n",
      "Model: SGDClassifier\n",
      "val accuracy 0.7413793103448276\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Violent       0.26      0.23      0.24        84\n",
      " not Violent       0.83      0.86      0.84       380\n",
      "\n",
      "    accuracy                           0.74       464\n",
      "   macro avg       0.55      0.54      0.54       464\n",
      "weighted avg       0.73      0.74      0.73       464\n",
      "\n",
      "\n",
      "Model: KNeighborsClassifier\n",
      "val accuracy 0.7607758620689655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Violent       0.15      0.07      0.10        84\n",
      " not Violent       0.82      0.91      0.86       380\n",
      "\n",
      "    accuracy                           0.76       464\n",
      "   macro avg       0.49      0.49      0.48       464\n",
      "weighted avg       0.70      0.76      0.72       464\n",
      "\n",
      "\n",
      "Model: MultinomialNB\n",
      "val accuracy 0.8060344827586207\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Violent       0.35      0.08      0.13        84\n",
      " not Violent       0.83      0.97      0.89       380\n",
      "\n",
      "    accuracy                           0.81       464\n",
      "   macro avg       0.59      0.52      0.51       464\n",
      "weighted avg       0.74      0.81      0.75       464\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Violent / not Violent\n",
    "responses_df_binary_main = binarize_classes(responses_df_clean, class_chosen=\"Violent\")\n",
    "train_and_evaluate(responses_df_binary_main, model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "20249e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression\n",
      "val accuracy 0.8987068965517241\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Racist       0.00      0.00      0.00        47\n",
      "  not Racist       0.90      1.00      0.95       417\n",
      "\n",
      "    accuracy                           0.90       464\n",
      "   macro avg       0.45      0.50      0.47       464\n",
      "weighted avg       0.81      0.90      0.85       464\n",
      "\n",
      "\n",
      "Model: RandomForestClassifier\n",
      "val accuracy 0.8987068965517241\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Racist       0.00      0.00      0.00        47\n",
      "  not Racist       0.90      1.00      0.95       417\n",
      "\n",
      "    accuracy                           0.90       464\n",
      "   macro avg       0.45      0.50      0.47       464\n",
      "weighted avg       0.81      0.90      0.85       464\n",
      "\n",
      "\n",
      "Model: DecisionTreeClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\modaj\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\modaj\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\modaj\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\modaj\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\modaj\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\modaj\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy 0.8318965517241379\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Racist       0.12      0.11      0.11        47\n",
      "  not Racist       0.90      0.91      0.91       417\n",
      "\n",
      "    accuracy                           0.83       464\n",
      "   macro avg       0.51      0.51      0.51       464\n",
      "weighted avg       0.82      0.83      0.83       464\n",
      "\n",
      "\n",
      "Model: SGDClassifier\n",
      "val accuracy 0.8146551724137931\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Racist       0.15      0.17      0.16        47\n",
      "  not Racist       0.90      0.89      0.90       417\n",
      "\n",
      "    accuracy                           0.81       464\n",
      "   macro avg       0.53      0.53      0.53       464\n",
      "weighted avg       0.83      0.81      0.82       464\n",
      "\n",
      "\n",
      "Model: KNeighborsClassifier\n",
      "val accuracy 0.8814655172413793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Racist       0.17      0.04      0.07        47\n",
      "  not Racist       0.90      0.98      0.94       417\n",
      "\n",
      "    accuracy                           0.88       464\n",
      "   macro avg       0.53      0.51      0.50       464\n",
      "weighted avg       0.83      0.88      0.85       464\n",
      "\n",
      "\n",
      "Model: MultinomialNB\n",
      "val accuracy 0.896551724137931\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Racist       0.33      0.02      0.04        47\n",
      "  not Racist       0.90      1.00      0.95       417\n",
      "\n",
      "    accuracy                           0.90       464\n",
      "   macro avg       0.62      0.51      0.49       464\n",
      "weighted avg       0.84      0.90      0.85       464\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Racist / not Racist\n",
    "responses_df_binary_main = binarize_classes(responses_df_clean, class_chosen=\"Racist\")\n",
    "train_and_evaluate(responses_df_binary_main, model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "50b626b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression\n",
      "val accuracy 0.771551724137931\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Mockery       0.50      0.02      0.04       106\n",
      " not Mockery       0.77      0.99      0.87       358\n",
      "\n",
      "    accuracy                           0.77       464\n",
      "   macro avg       0.64      0.51      0.45       464\n",
      "weighted avg       0.71      0.77      0.68       464\n",
      "\n",
      "\n",
      "Model: RandomForestClassifier\n",
      "val accuracy 0.771551724137931\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Mockery       0.00      0.00      0.00       106\n",
      " not Mockery       0.77      1.00      0.87       358\n",
      "\n",
      "    accuracy                           0.77       464\n",
      "   macro avg       0.39      0.50      0.44       464\n",
      "weighted avg       0.60      0.77      0.67       464\n",
      "\n",
      "\n",
      "Model: DecisionTreeClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\modaj\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\modaj\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\modaj\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy 0.6724137931034483\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Mockery       0.29      0.31      0.30       106\n",
      " not Mockery       0.79      0.78      0.79       358\n",
      "\n",
      "    accuracy                           0.67       464\n",
      "   macro avg       0.54      0.55      0.54       464\n",
      "weighted avg       0.68      0.67      0.68       464\n",
      "\n",
      "\n",
      "Model: SGDClassifier\n",
      "val accuracy 0.6939655172413793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Mockery       0.30      0.25      0.27       106\n",
      " not Mockery       0.79      0.83      0.81       358\n",
      "\n",
      "    accuracy                           0.69       464\n",
      "   macro avg       0.54      0.54      0.54       464\n",
      "weighted avg       0.67      0.69      0.68       464\n",
      "\n",
      "\n",
      "Model: KNeighborsClassifier\n",
      "val accuracy 0.7262931034482759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Mockery       0.35      0.23      0.27       106\n",
      " not Mockery       0.79      0.87      0.83       358\n",
      "\n",
      "    accuracy                           0.73       464\n",
      "   macro avg       0.57      0.55      0.55       464\n",
      "weighted avg       0.69      0.73      0.70       464\n",
      "\n",
      "\n",
      "Model: MultinomialNB\n",
      "val accuracy 0.7413793103448276\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Mockery       0.27      0.08      0.12       106\n",
      " not Mockery       0.77      0.94      0.85       358\n",
      "\n",
      "    accuracy                           0.74       464\n",
      "   macro avg       0.52      0.51      0.48       464\n",
      "weighted avg       0.66      0.74      0.68       464\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mockery / not Mockery\n",
    "responses_df_binary_main = binarize_classes(responses_df_clean, class_chosen=\"Mockery\")\n",
    "train_and_evaluate(responses_df_binary_main, model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f610d911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression\n",
      "val accuracy 0.9094827586206896\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "    Sexual harrasment       0.00      0.00      0.00        42\n",
      "not Sexual harrasment       0.91      1.00      0.95       422\n",
      "\n",
      "             accuracy                           0.91       464\n",
      "            macro avg       0.45      0.50      0.48       464\n",
      "         weighted avg       0.83      0.91      0.87       464\n",
      "\n",
      "\n",
      "Model: RandomForestClassifier\n",
      "val accuracy 0.9094827586206896\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "    Sexual harrasment       0.00      0.00      0.00        42\n",
      "not Sexual harrasment       0.91      1.00      0.95       422\n",
      "\n",
      "             accuracy                           0.91       464\n",
      "            macro avg       0.45      0.50      0.48       464\n",
      "         weighted avg       0.83      0.91      0.87       464\n",
      "\n",
      "\n",
      "Model: DecisionTreeClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\modaj\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\modaj\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\modaj\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\modaj\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\modaj\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\modaj\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy 0.8814655172413793\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "    Sexual harrasment       0.24      0.14      0.18        42\n",
      "not Sexual harrasment       0.92      0.95      0.94       422\n",
      "\n",
      "             accuracy                           0.88       464\n",
      "            macro avg       0.58      0.55      0.56       464\n",
      "         weighted avg       0.86      0.88      0.87       464\n",
      "\n",
      "\n",
      "Model: SGDClassifier\n",
      "val accuracy 0.834051724137931\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "    Sexual harrasment       0.14      0.17      0.15        42\n",
      "not Sexual harrasment       0.92      0.90      0.91       422\n",
      "\n",
      "             accuracy                           0.83       464\n",
      "            macro avg       0.53      0.53      0.53       464\n",
      "         weighted avg       0.85      0.83      0.84       464\n",
      "\n",
      "\n",
      "Model: KNeighborsClassifier\n",
      "val accuracy 0.8922413793103449\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "    Sexual harrasment       0.17      0.05      0.07        42\n",
      "not Sexual harrasment       0.91      0.98      0.94       422\n",
      "\n",
      "             accuracy                           0.89       464\n",
      "            macro avg       0.54      0.51      0.51       464\n",
      "         weighted avg       0.84      0.89      0.86       464\n",
      "\n",
      "\n",
      "Model: MultinomialNB\n",
      "val accuracy 0.9073275862068966\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "    Sexual harrasment       0.33      0.02      0.04        42\n",
      "not Sexual harrasment       0.91      1.00      0.95       422\n",
      "\n",
      "             accuracy                           0.91       464\n",
      "            macro avg       0.62      0.51      0.50       464\n",
      "         weighted avg       0.86      0.91      0.87       464\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sexual harrasment / not Sexual harrasment\n",
    "responses_df_binary_main = binarize_classes(responses_df_clean, class_chosen=\"Sexual harrasment\")\n",
    "train_and_evaluate(responses_df_binary_main, model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "792ba4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression\n",
      "val accuracy 0.8987068965517241\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Racist       0.00      0.00      0.00        47\n",
      "  not Racist       0.90      1.00      0.95       417\n",
      "\n",
      "    accuracy                           0.90       464\n",
      "   macro avg       0.45      0.50      0.47       464\n",
      "weighted avg       0.81      0.90      0.85       464\n",
      "\n",
      "\n",
      "Model: RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\modaj\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\modaj\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\modaj\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\modaj\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\modaj\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\modaj\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy 0.8987068965517241\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Racist       0.00      0.00      0.00        47\n",
      "  not Racist       0.90      1.00      0.95       417\n",
      "\n",
      "    accuracy                           0.90       464\n",
      "   macro avg       0.45      0.50      0.47       464\n",
      "weighted avg       0.81      0.90      0.85       464\n",
      "\n",
      "\n",
      "Model: DecisionTreeClassifier\n",
      "val accuracy 0.8318965517241379\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Racist       0.12      0.11      0.11        47\n",
      "  not Racist       0.90      0.91      0.91       417\n",
      "\n",
      "    accuracy                           0.83       464\n",
      "   macro avg       0.51      0.51      0.51       464\n",
      "weighted avg       0.82      0.83      0.83       464\n",
      "\n",
      "\n",
      "Model: SGDClassifier\n",
      "val accuracy 0.8125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Racist       0.14      0.17      0.16        47\n",
      "  not Racist       0.90      0.88      0.89       417\n",
      "\n",
      "    accuracy                           0.81       464\n",
      "   macro avg       0.52      0.53      0.52       464\n",
      "weighted avg       0.83      0.81      0.82       464\n",
      "\n",
      "\n",
      "Model: KNeighborsClassifier\n",
      "val accuracy 0.8814655172413793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Racist       0.17      0.04      0.07        47\n",
      "  not Racist       0.90      0.98      0.94       417\n",
      "\n",
      "    accuracy                           0.88       464\n",
      "   macro avg       0.53      0.51      0.50       464\n",
      "weighted avg       0.83      0.88      0.85       464\n",
      "\n",
      "\n",
      "Model: MultinomialNB\n",
      "val accuracy 0.896551724137931\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Racist       0.33      0.02      0.04        47\n",
      "  not Racist       0.90      1.00      0.95       417\n",
      "\n",
      "    accuracy                           0.90       464\n",
      "   macro avg       0.62      0.51      0.49       464\n",
      "weighted avg       0.84      0.90      0.85       464\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Racist / not Racist\n",
    "responses_df_binary_main = binarize_classes(responses_df_clean, class_chosen=\"Racist\")\n",
    "train_and_evaluate(responses_df_binary_main, model_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mc-tf",
   "language": "python",
   "name": "mc-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
