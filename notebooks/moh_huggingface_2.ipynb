{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "B7cRAk-vtlrH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B7cRAk-vtlrH",
    "outputId": "bf1f3996-48bf-4527-80b5-130a960ddcc9",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# !pip install datasets transformers evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cff9b0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\modaj\\anaconda3\\envs\\DL-torch\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfbda94",
   "metadata": {
    "id": "3bfbda94"
   },
   "source": [
    "## `data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "708f0162",
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_df = pd.read_csv(\"../data/moh_QA_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea8a9001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>question_description</th>\n",
       "      <th>answer_category_num</th>\n",
       "      <th>question_description_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>وزير الخارجية اللبناني جبران باسيل قال في سلسل...</td>\n",
       "      <td>Religious affiliation</td>\n",
       "      <td>وزير خارجي لبناني جبران باسيل سلسله تغريد عقب ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>سورية بلد الحضارات تربطها بعلية او بحيوان</td>\n",
       "      <td>Violent</td>\n",
       "      <td>سوري بلد حضاره ربط عليه حيوان</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4246</td>\n",
       "      <td>تقتلون وسام الحسن وتترحموعلية من أي أصناف المخ...</td>\n",
       "      <td>Racist</td>\n",
       "      <td>قتل وسام حسن وتترحموعليه اي صنف مخلوق انتم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5304</td>\n",
       "      <td>معك خبر انو بلدة قطر متل ما سميتا مساحتها اكبر...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>معك نوي بلد قطر متل سمي مساحه اكبر لبنان ل عيب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1706</td>\n",
       "      <td>للامانه قوت الموسم اللي طاف كان هوا بس متحمس ح...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>امانه قوت موسم ل ي طاف هوا متحمس حق الجاي ان ا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3132</th>\n",
       "      <td>3720</td>\n",
       "      <td>كلامك هراء من دون اي قيمة تذكر انت بلوة من الب...</td>\n",
       "      <td>Violent</td>\n",
       "      <td>كلام هراء قيمه ذكر بلا البلوات منتقل قتل قتيل ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3133</th>\n",
       "      <td>7784</td>\n",
       "      <td>راح خبرك شو شايفة ب جبران باسيل</td>\n",
       "      <td>Normal</td>\n",
       "      <td>خبر شو شايفه جبران باسيل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3134</th>\n",
       "      <td>1318</td>\n",
       "      <td>كلمة جبران باسيل أخجلته وأخجلت كل الأمة العربية</td>\n",
       "      <td>Sexual harrasment</td>\n",
       "      <td>كلمه جبران باسيل اخجل اخجل امه عربي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3135</th>\n",
       "      <td>3153</td>\n",
       "      <td>انا مش عم خوفك يا قراع انا عم قلك انقبر انقلع ...</td>\n",
       "      <td>Violent</td>\n",
       "      <td>مش عم خوف يا قراع عم قل انقبر انقلع خلق يا قرد...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3136</th>\n",
       "      <td>1786</td>\n",
       "      <td>إنت و حريمك عواهر</td>\n",
       "      <td>Sexual harrasment</td>\n",
       "      <td>انت حريم عاهره</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3137 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      question_id                               question_description  \\\n",
       "0               1  وزير الخارجية اللبناني جبران باسيل قال في سلسل...   \n",
       "1               2          سورية بلد الحضارات تربطها بعلية او بحيوان   \n",
       "2            4246  تقتلون وسام الحسن وتترحموعلية من أي أصناف المخ...   \n",
       "3            5304  معك خبر انو بلدة قطر متل ما سميتا مساحتها اكبر...   \n",
       "4            1706  للامانه قوت الموسم اللي طاف كان هوا بس متحمس ح...   \n",
       "...           ...                                                ...   \n",
       "3132         3720  كلامك هراء من دون اي قيمة تذكر انت بلوة من الب...   \n",
       "3133         7784                    راح خبرك شو شايفة ب جبران باسيل   \n",
       "3134         1318    كلمة جبران باسيل أخجلته وأخجلت كل الأمة العربية   \n",
       "3135         3153  انا مش عم خوفك يا قراع انا عم قلك انقبر انقلع ...   \n",
       "3136         1786                                 إنت و حريمك عواهر    \n",
       "\n",
       "        answer_category_num                         question_description_clean  \n",
       "0     Religious affiliation  وزير خارجي لبناني جبران باسيل سلسله تغريد عقب ...  \n",
       "1                   Violent                      سوري بلد حضاره ربط عليه حيوان  \n",
       "2                    Racist         قتل وسام حسن وتترحموعليه اي صنف مخلوق انتم  \n",
       "3                    Normal  معك نوي بلد قطر متل سمي مساحه اكبر لبنان ل عيب...  \n",
       "4                    Normal  امانه قوت موسم ل ي طاف هوا متحمس حق الجاي ان ا...  \n",
       "...                     ...                                                ...  \n",
       "3132                Violent  كلام هراء قيمه ذكر بلا البلوات منتقل قتل قتيل ...  \n",
       "3133                 Normal                           خبر شو شايفه جبران باسيل  \n",
       "3134      Sexual harrasment                كلمه جبران باسيل اخجل اخجل امه عربي  \n",
       "3135                Violent  مش عم خوف يا قراع عم قل انقبر انقلع خلق يا قرد...  \n",
       "3136      Sexual harrasment                                     انت حريم عاهره  \n",
       "\n",
       "[3137 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20fed47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = QA_df[[\"answer_category_num\", \"question_description_clean\"]].copy().\\\n",
    "rename(columns={\"question_description_clean\": \"text\", \"answer_category_num\": \"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dcf88f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# le = LabelEncoder()\n",
    "# clean_data[\"label\"] = le.fit_transform(clean_data[\"label\"])\n",
    "# clean_data[\"label\"] = clean_data[\"label\"].astype(np.float32)\n",
    "# clean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b146883",
   "metadata": {},
   "source": [
    "## `Model #1`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79203025",
   "metadata": {},
   "source": [
    "**`Name: bert-base-cased`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0df9ed0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\modaj\\anaconda3\\envs\\DL-torch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import Dataset, Features, Value, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf2b2e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = list(clean_data['label'].unique())\n",
    "input_features = Features({'text': Value('string'), 'label': ClassLabel(names=class_names)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7jvq_QmayQh8",
   "metadata": {
    "id": "7jvq_QmayQh8"
   },
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(df=clean_data, features=input_features).train_test_split(test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "zL5UxD8E02Lo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zL5UxD8E02Lo",
    "outputId": "c59eaa15-bd82-47b2-9941-84966dc2d5fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2666\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 471\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "G4Rtr_TF2K5F",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "36d79cb206b24af8b45970f2da5d52b2",
      "d86118687d64415091e331cf38bc1b3b",
      "2f8e532fe4734999906b3a300cc42f5b",
      "cf9d1caaf9074e20af4312cf2729226b",
      "b229ea6d57114544b817da8d41e8185a",
      "d2390de8f99a4f33941d99ee10178f21",
      "8d187893389d4c9fb2ea5c36de0d07b0",
      "f02ed400ea7a4f32b9342d90413a3bd4",
      "df5a7e8cd4fb4fa68d915d5d831e8f35",
      "817734344829447ea2b02a2b450966fd",
      "81d0e0dd48dc4d4f852e9405dd89a2cd",
      "6da82680dd0d40888347b72314ce3872",
      "1f64c49e5d2c40c99a1092406df06e8d",
      "e39e46a9cfe6461da49e3f4b759504bf",
      "a241863ddbbb4c5e8d79a5ee7c677085",
      "d41734acd9274ed69199a882ce31b225",
      "300a9a70c8a54f03bc1a2da69222c50c",
      "3f76c5c6bf604a5ebfbdbb87a7550ce9",
      "6acacf94af3140aaafb88c54de85f141",
      "283365b5551b4282adbbb2aa8ba78408",
      "389d381a2457446684dc844e0bc84454",
      "fb5c6e9c169745a1a7bdab62c7774a73"
     ]
    },
    "id": "G4Rtr_TF2K5F",
    "outputId": "5e83cf9f-7dd3-400e-b3b6-37b608de19f6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  3.75ba/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.40ba/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33qLcWnZ4BTs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33qLcWnZ4BTs",
    "outputId": "87692247-069e-4eda-a86c-4cd2a2975565",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2BTX_-z-4c-0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2BTX_-z-4c-0",
    "outputId": "1232ec00-47aa-458b-b498-7d5edca0500e"
   },
   "outputs": [],
   "source": [
    "# ERROR\n",
    "# clf_metrics = evaluate.combine( [\n",
    "#     evaluate.load(\"accuracy\", average=\"weighted\"),\n",
    "#     evaluate.load(\"precision\", average=\"weighted\"),\n",
    "#     evaluate.load(\"recall\", average=\"weighted\"),\n",
    "#     evaluate.load(\"f1\", average=\"weighted\")\n",
    "# ])\n",
    "\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "precision_metric = evaluate.load(\"precision\")\n",
    "recall_metric = evaluate.load(\"recall\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    results = {}\n",
    "    results.update(accuracy_metric.compute(predictions=predictions, references = labels))\n",
    "    results.update(precision_metric.compute(predictions=predictions, references = labels, average=\"macro\"))\n",
    "    results.update(recall_metric.compute(predictions=predictions, references = labels, average=\"macro\"))\n",
    "    results.update(f1_metric.compute(predictions=predictions, references = labels, average=\"macro\"))\n",
    "    \n",
    "    return results\n",
    "    # return clf_metrics.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\", num_train_epochs=10,\n",
    "                                  per_device_train_batch_size=4, per_device_eval_batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "-jsDiUJL5eSZ",
   "metadata": {
    "id": "-jsDiUJL5eSZ"
   },
   "outputs": [],
   "source": [
    "train_dataset = tokenized_datasets[\"train\"] \n",
    "eval_dataset = tokenized_datasets[\"test\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "CwYe1nkK4iVC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "CwYe1nkK4iVC",
    "outputId": "8935b81b-823a-4825-e95f-0ea4706cec6d",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\modaj\\anaconda3\\envs\\DL-torch\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2666\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6670\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6670' max='6670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6670/6670 46:05, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.757600</td>\n",
       "      <td>1.685380</td>\n",
       "      <td>0.292994</td>\n",
       "      <td>0.048832</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.075534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.765300</td>\n",
       "      <td>1.678109</td>\n",
       "      <td>0.292994</td>\n",
       "      <td>0.048832</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.075534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.761500</td>\n",
       "      <td>1.688786</td>\n",
       "      <td>0.242038</td>\n",
       "      <td>0.040340</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.064957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.748300</td>\n",
       "      <td>1.688248</td>\n",
       "      <td>0.242038</td>\n",
       "      <td>0.040340</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.064957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.750600</td>\n",
       "      <td>1.700947</td>\n",
       "      <td>0.242038</td>\n",
       "      <td>0.040340</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.064957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.745000</td>\n",
       "      <td>1.677162</td>\n",
       "      <td>0.292994</td>\n",
       "      <td>0.048832</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.075534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.748800</td>\n",
       "      <td>1.693741</td>\n",
       "      <td>0.242038</td>\n",
       "      <td>0.040340</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.064957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.747000</td>\n",
       "      <td>1.685030</td>\n",
       "      <td>0.242038</td>\n",
       "      <td>0.040340</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.064957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.743900</td>\n",
       "      <td>1.685195</td>\n",
       "      <td>0.242038</td>\n",
       "      <td>0.040340</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.064957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.745500</td>\n",
       "      <td>1.683461</td>\n",
       "      <td>0.242038</td>\n",
       "      <td>0.040340</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.064957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to test_trainer\\checkpoint-500\n",
      "Configuration saved in test_trainer\\checkpoint-500\\config.json\n",
      "Model weights saved in test_trainer\\checkpoint-500\\pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 471\n",
      "  Batch size = 4\n",
      "C:\\Users\\modaj\\anaconda3\\envs\\DL-torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to test_trainer\\checkpoint-1000\n",
      "Configuration saved in test_trainer\\checkpoint-1000\\config.json\n",
      "Model weights saved in test_trainer\\checkpoint-1000\\pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 471\n",
      "  Batch size = 4\n",
      "C:\\Users\\modaj\\anaconda3\\envs\\DL-torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to test_trainer\\checkpoint-1500\n",
      "Configuration saved in test_trainer\\checkpoint-1500\\config.json\n",
      "Model weights saved in test_trainer\\checkpoint-1500\\pytorch_model.bin\n",
      "Saving model checkpoint to test_trainer\\checkpoint-2000\n",
      "Configuration saved in test_trainer\\checkpoint-2000\\config.json\n",
      "Model weights saved in test_trainer\\checkpoint-2000\\pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 471\n",
      "  Batch size = 4\n",
      "C:\\Users\\modaj\\anaconda3\\envs\\DL-torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to test_trainer\\checkpoint-2500\n",
      "Configuration saved in test_trainer\\checkpoint-2500\\config.json\n",
      "Model weights saved in test_trainer\\checkpoint-2500\\pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 471\n",
      "  Batch size = 4\n",
      "C:\\Users\\modaj\\anaconda3\\envs\\DL-torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to test_trainer\\checkpoint-3000\n",
      "Configuration saved in test_trainer\\checkpoint-3000\\config.json\n",
      "Model weights saved in test_trainer\\checkpoint-3000\\pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 471\n",
      "  Batch size = 4\n",
      "C:\\Users\\modaj\\anaconda3\\envs\\DL-torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to test_trainer\\checkpoint-3500\n",
      "Configuration saved in test_trainer\\checkpoint-3500\\config.json\n",
      "Model weights saved in test_trainer\\checkpoint-3500\\pytorch_model.bin\n",
      "Saving model checkpoint to test_trainer\\checkpoint-4000\n",
      "Configuration saved in test_trainer\\checkpoint-4000\\config.json\n",
      "Model weights saved in test_trainer\\checkpoint-4000\\pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 471\n",
      "  Batch size = 4\n",
      "C:\\Users\\modaj\\anaconda3\\envs\\DL-torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to test_trainer\\checkpoint-4500\n",
      "Configuration saved in test_trainer\\checkpoint-4500\\config.json\n",
      "Model weights saved in test_trainer\\checkpoint-4500\\pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 471\n",
      "  Batch size = 4\n",
      "C:\\Users\\modaj\\anaconda3\\envs\\DL-torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to test_trainer\\checkpoint-5000\n",
      "Configuration saved in test_trainer\\checkpoint-5000\\config.json\n",
      "Model weights saved in test_trainer\\checkpoint-5000\\pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 471\n",
      "  Batch size = 4\n",
      "C:\\Users\\modaj\\anaconda3\\envs\\DL-torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to test_trainer\\checkpoint-5500\n",
      "Configuration saved in test_trainer\\checkpoint-5500\\config.json\n",
      "Model weights saved in test_trainer\\checkpoint-5500\\pytorch_model.bin\n",
      "Saving model checkpoint to test_trainer\\checkpoint-6000\n",
      "Configuration saved in test_trainer\\checkpoint-6000\\config.json\n",
      "Model weights saved in test_trainer\\checkpoint-6000\\pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 471\n",
      "  Batch size = 4\n",
      "C:\\Users\\modaj\\anaconda3\\envs\\DL-torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to test_trainer\\checkpoint-6500\n",
      "Configuration saved in test_trainer\\checkpoint-6500\\config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer\\checkpoint-6500\\pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 471\n",
      "  Batch size = 4\n",
      "C:\\Users\\modaj\\anaconda3\\envs\\DL-torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6670, training_loss=1.7504071511607477, metrics={'train_runtime': 2768.0496, 'train_samples_per_second': 9.631, 'train_steps_per_second': 2.41, 'total_flos': 7014792658821120.0, 'train_loss': 1.7504071511607477, 'epoch': 10.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b472e8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 471\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\modaj\\anaconda3\\envs\\DL-torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-0.13298853,  0.28291032, -0.32345778,  0.6375057 ,  0.5272559 ,\n",
       "        -0.29504663],\n",
       "       [-0.13299048,  0.28290936, -0.32345915,  0.6375077 ,  0.5272541 ,\n",
       "        -0.29504713],\n",
       "       [-0.13299043,  0.28290892, -0.32345733,  0.637506  ,  0.52725387,\n",
       "        -0.29504663],\n",
       "       ...,\n",
       "       [-0.13298889,  0.28291   , -0.32345816,  0.637507  ,  0.52725506,\n",
       "        -0.29504618],\n",
       "       [-0.13298917,  0.28290927, -0.32345822,  0.6375081 ,  0.5272542 ,\n",
       "        -0.2950466 ],\n",
       "       [-0.13298766,  0.2829117 , -0.32345694,  0.63750774,  0.5272555 ,\n",
       "        -0.29504505]], dtype=float32), label_ids=array([3, 3, 0, 3, 4, 0, 4, 4, 4, 0, 1, 5, 3, 4, 2, 4, 1, 5, 4, 3, 4, 1,\n",
       "       2, 1, 4, 1, 1, 5, 1, 3, 3, 3, 5, 2, 3, 2, 4, 1, 0, 3, 2, 3, 3, 4,\n",
       "       2, 4, 0, 0, 1, 4, 1, 4, 3, 3, 4, 4, 0, 4, 4, 0, 3, 2, 4, 4, 4, 0,\n",
       "       4, 1, 3, 3, 4, 0, 1, 4, 4, 3, 3, 4, 3, 3, 5, 1, 2, 4, 4, 4, 3, 0,\n",
       "       4, 0, 0, 4, 0, 4, 4, 3, 1, 3, 4, 1, 4, 4, 0, 3, 4, 1, 5, 1, 1, 4,\n",
       "       4, 0, 1, 5, 5, 1, 1, 4, 4, 3, 4, 0, 2, 3, 3, 3, 4, 4, 3, 3, 2, 3,\n",
       "       5, 3, 2, 2, 0, 1, 4, 0, 4, 1, 4, 4, 3, 3, 5, 3, 1, 0, 1, 4, 4, 4,\n",
       "       2, 3, 5, 4, 1, 2, 1, 2, 2, 5, 3, 3, 3, 2, 3, 4, 4, 5, 0, 3, 0, 4,\n",
       "       3, 1, 1, 4, 3, 5, 3, 3, 4, 4, 4, 4, 2, 4, 1, 3, 1, 1, 5, 3, 1, 1,\n",
       "       3, 0, 1, 5, 1, 5, 4, 3, 3, 3, 3, 5, 4, 3, 3, 1, 3, 3, 4, 4, 3, 4,\n",
       "       4, 4, 3, 4, 3, 1, 4, 1, 5, 2, 1, 3, 2, 1, 3, 3, 1, 4, 4, 3, 5, 3,\n",
       "       5, 4, 3, 1, 4, 2, 4, 5, 4, 2, 5, 0, 4, 1, 3, 4, 0, 1, 3, 5, 4, 3,\n",
       "       0, 4, 4, 3, 3, 3, 3, 3, 2, 4, 1, 3, 4, 4, 4, 5, 4, 1, 4, 5, 1, 4,\n",
       "       2, 0, 1, 4, 2, 2, 4, 4, 2, 1, 3, 1, 1, 3, 3, 1, 1, 4, 4, 1, 1, 5,\n",
       "       2, 0, 1, 3, 5, 4, 2, 4, 0, 1, 1, 2, 2, 4, 4, 5, 5, 1, 4, 4, 1, 5,\n",
       "       2, 2, 1, 4, 3, 0, 0, 0, 1, 3, 4, 3, 1, 1, 4, 5, 3, 4, 0, 4, 1, 5,\n",
       "       3, 2, 3, 3, 0, 0, 1, 2, 2, 2, 3, 5, 1, 4, 3, 1, 1, 4, 4, 4, 3, 4,\n",
       "       1, 2, 1, 4, 3, 3, 1, 4, 2, 1, 3, 1, 3, 1, 4, 1, 4, 4, 1, 3, 3, 1,\n",
       "       3, 4, 4, 1, 0, 2, 4, 0, 5, 4, 1, 3, 5, 4, 3, 3, 5, 1, 4, 5, 3, 3,\n",
       "       3, 4, 2, 5, 4, 0, 1, 4, 1, 5, 4, 1, 4, 4, 4, 3, 4, 1, 4, 4, 3, 4,\n",
       "       4, 2, 4, 3, 1, 2, 3, 4, 3, 3, 3, 1, 3, 0, 1, 1, 0, 4, 1, 5, 0, 3,\n",
       "       1, 4, 1, 3, 1, 4, 4, 3, 3], dtype=int64), metrics={'test_loss': 1.68346107006073, 'test_accuracy': 0.24203821656050956, 'test_precision': 0.040339702760084924, 'test_recall': 0.16666666666666666, 'test_f1': 0.06495726495726496, 'test_runtime': 16.0758, 'test_samples_per_second': 29.299, 'test_steps_per_second': 7.34})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.predict(eval_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1a3dc3",
   "metadata": {},
   "source": [
    "## `Model #2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "930b19b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m clf_metrics \u001b[38;5;241m=\u001b[39m evaluate\u001b[38;5;241m.\u001b[39mcombine( [\n\u001b[0;32m      2\u001b[0m     evaluate\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      3\u001b[0m     evaluate\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m\"\u001b[39m, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      4\u001b[0m     evaluate\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m\"\u001b[39m, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      5\u001b[0m     evaluate\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m ])\n\u001b[1;32m----> 8\u001b[0m \u001b[43mclf_metrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreferences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL-torch\\lib\\site-packages\\evaluate\\module.py:862\u001b[0m, in \u001b[0;36mCombinedEvaluations.compute\u001b[1;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[0;32m    860\u001b[0m     batch \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m\"\u001b[39m: predictions, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreferences\u001b[39m\u001b[38;5;124m\"\u001b[39m: references, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m    861\u001b[0m     batch \u001b[38;5;241m=\u001b[39m {input_name: batch[input_name] \u001b[38;5;28;01mfor\u001b[39;00m input_name \u001b[38;5;129;01min\u001b[39;00m evaluation_module\u001b[38;5;241m.\u001b[39m_feature_names()}\n\u001b[1;32m--> 862\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(evaluation_module\u001b[38;5;241m.\u001b[39mcompute(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbatch))\n\u001b[0;32m    864\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_results(results)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL-torch\\lib\\site-packages\\evaluate\\module.py:444\u001b[0m, in \u001b[0;36mEvaluationModule.compute\u001b[1;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[0;32m    442\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {input_name: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[input_name] \u001b[38;5;28;01mfor\u001b[39;00m input_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_names()}\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m temp_seed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed):\n\u001b[1;32m--> 444\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcompute_kwargs)\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_writer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\.cache\\huggingface\\modules\\evaluate_modules\\metrics\\evaluate-metric--precision\\4e7f439a346715f68500ce6f2be82bf3272abd3f20bdafd203a2c4f85b61dd5f\\precision.py:136\u001b[0m, in \u001b[0;36mPrecision._compute\u001b[1;34m(self, predictions, references, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compute\u001b[39m(\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    128\u001b[0m     predictions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    134\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    135\u001b[0m ):\n\u001b[1;32m--> 136\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreferences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(score) \u001b[38;5;28;01mif\u001b[39;00m score\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m score}\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL-torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1776\u001b[0m, in \u001b[0;36mprecision_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1647\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprecision_score\u001b[39m(\n\u001b[0;32m   1648\u001b[0m     y_true,\n\u001b[0;32m   1649\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1655\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1656\u001b[0m ):\n\u001b[0;32m   1657\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[0;32m   1658\u001b[0m \n\u001b[0;32m   1659\u001b[0m \u001b[38;5;124;03m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;124;03m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1776\u001b[0m     p, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1777\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1778\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1779\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1780\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1781\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1782\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprecision\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1783\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1784\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1785\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL-torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1563\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m beta \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1562\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta should be >=0 in the F-beta score\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1563\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1566\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DL-torch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1381\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1379\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1380\u001b[0m             average_options\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1381\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1382\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget is \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m but average=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1383\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoose another average setting, one of \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (y_type, average_options)\n\u001b[0;32m   1384\u001b[0m         )\n\u001b[0;32m   1385\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1386\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1387\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote that pos_label (set to \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) is ignored when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1388\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage != \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m). You may use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1392\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b275329e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869e6c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b6d238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7eccaaa",
   "metadata": {},
   "source": [
    "## ref"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7bbe59",
   "metadata": {},
   "source": [
    "- https://discuss.huggingface.co/t/combining-metrics-for-multiclass-predictions-evaluations/21792/10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL-torch",
   "language": "python",
   "name": "dl-torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
