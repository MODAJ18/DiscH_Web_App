{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dde02c7",
   "metadata": {},
   "source": [
    "## `1) Libraries`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78c665b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb96bbf2",
   "metadata": {},
   "source": [
    "## `2) Getting Data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a968678f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dbname': 'd1mikus7g5uss8',\n",
       " 'host': 'ec2-99-81-68-240.eu-west-1.compute.amazonaws.com',\n",
       " 'port': '5432',\n",
       " 'user': 'iohznziolcottb',\n",
       " 'password': '5a812ea29f6142328bc2afab03e48e6462939babe87610342cdf12e2d357a4f0',\n",
       " 'sslmode': 'require'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "creds = {'dbname': 'd1mikus7g5uss8',\n",
    " 'host': 'ec2-99-81-68-240.eu-west-1.compute.amazonaws.com',\n",
    " 'port': '5432',\n",
    " 'user': 'iohznziolcottb',\n",
    " 'password': '5a812ea29f6142328bc2afab03e48e6462939babe87610342cdf12e2d357a4f0',\n",
    " 'sslmode': 'require'}\n",
    "\n",
    "creds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9fba4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(host=creds['host'], database=creds['dbname'],\n",
    "                                user=creds['user'],\n",
    "                                password=creds['password'])\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8363b0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_Query = 'select q.description, q.question_id, a.answer_category_num, a.answer_justification, a.answer_upvote, \\\n",
    "              a.account_id_id from public.\"DiscH_prototype_question\" q RIGHT JOIN public.\"DiscH_prototype_answer\" a \\\n",
    "ON a.question_id_id=q.question_id'\n",
    "cur.execute(select_Query)\n",
    "QAs = cur.fetchall() \n",
    "QA_col = [\"question_description\", \"question_id\", \"answer_category_num\", \"answer_justification\", \"answer_upvote\", \"account_id\"]\n",
    "QA_df = pd.DataFrame(QAs, columns=QA_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bbf913",
   "metadata": {},
   "source": [
    "## `3) Preparation and Cleaning`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0502c9",
   "metadata": {},
   "source": [
    "### - Preparing DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6eb19d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# import the dediacritization tool\n",
    "from camel_tools.utils.dediac import dediac_ar\n",
    "\n",
    "# Reducing Orthographic Ambiguity\n",
    "from camel_tools.utils.normalize import normalize_alef_maksura_ar\n",
    "from camel_tools.utils.normalize import normalize_alef_ar\n",
    "from camel_tools.utils.normalize import normalize_teh_marbuta_ar\n",
    "\n",
    "# toknenization\n",
    "from camel_tools.tokenizers.word import simple_word_tokenize\n",
    "\n",
    "# Morphological Disambiguation (Maximum Likelihood Disambiguator)\n",
    "from camel_tools.disambig.mle import MLEDisambiguator\n",
    "mle = MLEDisambiguator.pretrained() # instantiation fo MLE disambiguator\n",
    "\n",
    "# tokenization / lemmatization (choosing approach that best fit the project)\n",
    "from camel_tools.tokenizers.morphological import MorphologicalTokenizer\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fc1c22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(df):\n",
    "    df = df.copy().rename(columns={\"description\":'question_description'})\n",
    "    df  = df[[\"question_id\", 'question_description', 'answer_category_num']]\n",
    "    df.drop_duplicates(subset='question_description', inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # checking how many comments have different votes\n",
    "    for i, row in df.iterrows():\n",
    "\n",
    "        comment = row.question_description\n",
    "\n",
    "        # getting the dataframe for that comment\n",
    "        temp_df = df[df.question_description == comment]\n",
    "\n",
    "        # how many unique answers that comment has\n",
    "        n_ = temp_df.answer_category_num.nunique()\n",
    "\n",
    "        # changing the answer_category_num to the most frequent one\n",
    "        if n_ >= 2:\n",
    "            most_voted_label = temp_df.answer_category_num.value_counts().index[0]\n",
    "            df.at[i, 'answer_category_num'] = most_voted_label\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9db8e237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA_df_xlsx = pd.read_excel(\"../data/responses_data.xlsx\")\n",
    "# QA_df_xlsx = QA_df_xlsx.copy().rename(columns={\"description\":'question_description'})\n",
    "# QA_df_xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07f42efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>question_description</th>\n",
       "      <th>answer_category_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>وزير الخارجية اللبناني جبران باسيل قال في سلسل...</td>\n",
       "      <td>Religious affiliation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>سورية بلد الحضارات تربطها بعلية او بحيوان</td>\n",
       "      <td>Violent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4246</td>\n",
       "      <td>تقتلون وسام الحسن وتترحموعلية من أي أصناف المخ...</td>\n",
       "      <td>Racist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5304</td>\n",
       "      <td>معك خبر انو بلدة قطر متل ما سميتا مساحتها اكبر...</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1706</td>\n",
       "      <td>للامانه قوت الموسم اللي طاف كان هوا بس متحمس ح...</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3132</th>\n",
       "      <td>3720</td>\n",
       "      <td>كلامك هراء من دون اي قيمة تذكر انت بلوة من الب...</td>\n",
       "      <td>Violent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3133</th>\n",
       "      <td>7784</td>\n",
       "      <td>راح خبرك شو شايفة ب جبران باسيل</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3134</th>\n",
       "      <td>1318</td>\n",
       "      <td>كلمة جبران باسيل أخجلته وأخجلت كل الأمة العربية</td>\n",
       "      <td>Sexual harrasment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3135</th>\n",
       "      <td>3153</td>\n",
       "      <td>انا مش عم خوفك يا قراع انا عم قلك انقبر انقلع ...</td>\n",
       "      <td>Violent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3136</th>\n",
       "      <td>1786</td>\n",
       "      <td>إنت و حريمك عواهر</td>\n",
       "      <td>Sexual harrasment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3137 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      question_id                               question_description  \\\n",
       "0               1  وزير الخارجية اللبناني جبران باسيل قال في سلسل...   \n",
       "1               2          سورية بلد الحضارات تربطها بعلية او بحيوان   \n",
       "2            4246  تقتلون وسام الحسن وتترحموعلية من أي أصناف المخ...   \n",
       "3            5304  معك خبر انو بلدة قطر متل ما سميتا مساحتها اكبر...   \n",
       "4            1706  للامانه قوت الموسم اللي طاف كان هوا بس متحمس ح...   \n",
       "...           ...                                                ...   \n",
       "3132         3720  كلامك هراء من دون اي قيمة تذكر انت بلوة من الب...   \n",
       "3133         7784                    راح خبرك شو شايفة ب جبران باسيل   \n",
       "3134         1318    كلمة جبران باسيل أخجلته وأخجلت كل الأمة العربية   \n",
       "3135         3153  انا مش عم خوفك يا قراع انا عم قلك انقبر انقلع ...   \n",
       "3136         1786                                 إنت و حريمك عواهر    \n",
       "\n",
       "        answer_category_num  \n",
       "0     Religious affiliation  \n",
       "1                   Violent  \n",
       "2                    Racist  \n",
       "3                    Normal  \n",
       "4                    Normal  \n",
       "...                     ...  \n",
       "3132                Violent  \n",
       "3133                 Normal  \n",
       "3134      Sexual harrasment  \n",
       "3135                Violent  \n",
       "3136      Sexual harrasment  \n",
       "\n",
       "[3137 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA_df_clean = prepare_df(QA_df)\n",
    "QA_df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beac3ae",
   "metadata": {},
   "source": [
    "### - Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43db7473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    return re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))',' ', text)\n",
    "\n",
    "def remove_html(text):\n",
    "    return BeautifulSoup(text, \"html.parser\").text\n",
    "\n",
    "symb_re = re.compile(r\"\"\"[!\"#$%&\\'()*+,-./:;<=>?@[\\\\\\]^_`{|}~،؟…«“\\\":\\\"…”]\"\"\")\n",
    "def remove_symbols(text: str) -> str:\n",
    "    return symb_re.sub(repl=\"\", string=text)\n",
    "\n",
    "multiple_space_re = re.compile(\"\\s{2,}\")\n",
    "def remove_multiple_whitespace(text):\n",
    "    return multiple_space_re.sub(repl=\" \", string=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a6b5744",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_word_list = pd.read_csv('../Data/stop_words/list.csv')['words'].to_list()\n",
    "tokenizer = MorphologicalTokenizer(mle, scheme='atbtok', diac=False) # atbseg scheme \n",
    "def text_clean(txt):\n",
    "    txt = remove_urls(txt)\n",
    "    txt = remove_html(txt)\n",
    "    \n",
    "    # remove stopwords\n",
    "    txt = ' '.join(word for word in txt.split() if word not in stop_word_list)\n",
    "    \n",
    "    # dediacritization\n",
    "    txt = dediac_ar(txt)\n",
    "    \n",
    "    # normalization: Reduce Orthographic Ambiguity and Dialectal Variation\n",
    "    txt = normalize_alef_maksura_ar(txt)\n",
    "    txt = normalize_alef_ar(txt)\n",
    "    txt = normalize_teh_marbuta_ar(txt)\n",
    "    \n",
    "    # normalization: Reducing Morphological Variation\n",
    "    tokens = simple_word_tokenize(txt)\n",
    "    disambig = mle.disambiguate(tokens)\n",
    "    lemmas = [d.analyses[0].analysis['lex'] for d in disambig]\n",
    "    tokens = tokenizer.tokenize(lemmas)\n",
    "    txt = ' '.join(tokens)\n",
    "    \n",
    "    # remove longation\n",
    "    txt = re.sub(\"[إأآا]\", \"ا\", txt)\n",
    "    txt = re.sub(\"ى\", \"ي\", txt)\n",
    "    txt = re.sub(\"ؤ\", \"ء\", txt)\n",
    "    txt = re.sub(\"ئ\", \"ء\", txt)\n",
    "    txt = re.sub(\"ة\", \"ه\", txt)\n",
    "    txt = re.sub(\"گ\", \"ك\", txt)\n",
    "    \n",
    "    # remove non-arabic words, or non-numbers, or non-english words in the text\n",
    "    txt = re.sub(r'[^a-zA-Z\\s0-9\\u0600-\\u06ff\\u0750-\\u077f\\ufb50-\\ufbc1\\ufbd3-\\ufd3f\\ufd50-\\ufd8f\\ufd50-\\ufd8f\\ufe70-\\ufefc\\uFDF0-\\uFDFD.0-9]+'\n",
    "                 ,' ', txt)\n",
    "    \n",
    "    # remove symbols\n",
    "    txt = remove_symbols(txt)\n",
    "    \n",
    "    # remove multiple whitespace\n",
    "    txt = remove_multiple_whitespace(txt)\n",
    "    \n",
    "    \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1c53a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_df_clean['question_description_clean'] = QA_df_clean['question_description'].apply(text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d2dfe09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1ba0254e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(QA_df_clean[\"question_description\"][i])\n",
    "# display(QA_df_clean[\"question_description_clean\"][i])\n",
    "# i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be08ab7f",
   "metadata": {},
   "source": [
    "### - removing frequent words, forming vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f613c469",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e7c9e870",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\modaj\\OneDrive\\Documents\\Personal\\Jobs\\SHAI\\intern - task 3\\haystack-venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "bag_of_words = count_vectorizer.fit_transform(QA_df_clean['question_description_clean'])\n",
    "feature_names = count_vectorizer.get_feature_names()\n",
    "word_frequencies = bag_of_words.toarray().sum(axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5fa05fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary = count_vectorizer.vocabulary_\n",
    "# vocabulary_terms = list(vocabulary.keys())\n",
    "# terms_to_remove = []\n",
    "\n",
    "# for term in vocabulary_terms:\n",
    "#     frequency = vocabulary[term]\n",
    "#     print(\"term: {} / frequency: {}\".format(term, frequency))\n",
    "#     print()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "089aa972",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = count_vectorizer.get_feature_names()\n",
    "word_frequencies = bag_of_words.toarray().sum(axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "dd825e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len vocab (before filtering): 7565\n",
      "len vocab (after filtering): 3214\n"
     ]
    }
   ],
   "source": [
    "word_occurence_set = list(zip(feature_names, word_frequencies))\n",
    "word_occurence_set_asc = sorted(word_occurence_set, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "vocabulary = []\n",
    "for wos in word_occurence_set_asc:\n",
    "    word, count = wos \n",
    "    \n",
    "    # frequently occuring words are filetered\n",
    "    if count > bag_of_words.shape[0] * 0.5:\n",
    "        continue\n",
    "    elif count <= 1:\n",
    "        continue\n",
    "    else:\n",
    "        vocabulary.append(word)\n",
    "\n",
    "print('len vocab (before filtering): {}'.format(len(word_occurence_set_asc)))\n",
    "print('len vocab (after filtering): {}'.format(len(vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "38264bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA_df_clean.to_csv(\"../moh_test/test_data/QA_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b6922f",
   "metadata": {},
   "source": [
    "## 4) `TF-IDF (testing model performance with cleaned data)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "79d28df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "b9d7df67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "29e532f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = QA_df_clean[[\"question_description_clean\", \"answer_category_num\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "a13ec459",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(QA_df_clean, test_size=0.15, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "8d357971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>question_description</th>\n",
       "      <th>answer_category_num</th>\n",
       "      <th>question_description_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2459</th>\n",
       "      <td>8807</td>\n",
       "      <td>اااه يافلسطين ااااه من ضعفنا اللهم لا تحسبنا و...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>اااه يافلسطين ااااه ضعف اللهم تحسب سال ضعف سام...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>6182</td>\n",
       "      <td>الله اكبر ع كل كلب بيكره وليد بيك بدنا نقصفلو ...</td>\n",
       "      <td>Racist</td>\n",
       "      <td>الله اكبر كلب بيكره وليد بك بدن نقصفلو رقبتوا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>3639</td>\n",
       "      <td>انت رئس الفساد</td>\n",
       "      <td>Violent</td>\n",
       "      <td>رءس فساد</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>1152</td>\n",
       "      <td>ياريت شعبك بيسمع واذا سمع يوقف واذا وقف يحدث ا...</td>\n",
       "      <td>Sexual harrasment</td>\n",
       "      <td>ياريت شعب بيسمع اذا سمع وقف اذا حدث فرقه شعب ل...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>7891</td>\n",
       "      <td>من وطأة التراث الديني مثلا المعركة الحاصلة الآ...</td>\n",
       "      <td>Religious affiliation</td>\n",
       "      <td>وطاه تراث ديني مثل معركه حاصل ان ماء ي زكاه فط...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      question_id                               question_description  \\\n",
       "2459         8807  اااه يافلسطين ااااه من ضعفنا اللهم لا تحسبنا و...   \n",
       "1365         6182  الله اكبر ع كل كلب بيكره وليد بيك بدنا نقصفلو ...   \n",
       "630          3639                                    انت رئس الفساد    \n",
       "1151         1152  ياريت شعبك بيسمع واذا سمع يوقف واذا وقف يحدث ا...   \n",
       "2060         7891  من وطأة التراث الديني مثلا المعركة الحاصلة الآ...   \n",
       "\n",
       "        answer_category_num                         question_description_clean  \n",
       "2459                 Normal  اااه يافلسطين ااااه ضعف اللهم تحسب سال ضعف سام...  \n",
       "1365                 Racist      الله اكبر كلب بيكره وليد بك بدن نقصفلو رقبتوا  \n",
       "630                 Violent                                           رءس فساد  \n",
       "1151      Sexual harrasment  ياريت شعب بيسمع اذا سمع وقف اذا حدث فرقه شعب ل...  \n",
       "2060  Religious affiliation  وطاه تراث ديني مثل معركه حاصل ان ماء ي زكاه فط...  "
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "edc4f312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer.fit(train_data[\"question_description_clean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "16fd43e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_tr = tfidf_vectorizer.transform(train_data['question_description_clean'])\n",
    "tfidf_val = tfidf_vectorizer.transform(test_data['question_description_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "ee3e7559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definitions\n",
    "LogReg_model = LogisticRegression()\n",
    "RandomForestClassifier_model = RandomForestClassifier(max_depth=3, random_state=0)\n",
    "\n",
    "MultinomialNB_model = MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)\n",
    "SGDClassifier_model = SGDClassifier(class_weight='balanced', penalty='l1')\n",
    "KNeighborsClassifier_model = KNeighborsClassifier(n_neighbors=3)\n",
    "DecisionTreeClassifier_model = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "models = [LogReg_model, RandomForestClassifier_model, DecisionTreeClassifier_model,\n",
    "          SGDClassifier_model,   \n",
    "          KNeighborsClassifier_model,  MultinomialNB_model]\n",
    "model_names = ['LogisticRegression', 'RandomForestClassifier', 'DecisionTreeClassifier',\n",
    "               'SGDClassifier', 'KNeighborsClassifier', 'MultinomialNB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "424b5624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2666, 7002), (2666,))"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = tfidf_tr, train_data['answer_category_num']\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "d3e89f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((471, 7002), (471,))"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test = tfidf_val, test_data['answer_category_num']\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "28542edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(X_tr, X_te, y_tr, y_te):\n",
    "    for i, model in enumerate(models):\n",
    "        print(f\"Model: {model_names[i]}\")\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_te)\n",
    "        print(\"----- METRIC -----\")\n",
    "        print('val accuracy %s' % accuracy_score(y_te, y_pred))\n",
    "#         print(\"----- PREDICTION DISTRIBUTION -----\")\n",
    "#         print(pd.Series(y_te).value_counts())\n",
    "#         print(pd.Series(y_pred).value_counts())\n",
    "#         print(\"----- CLASSIFICATION REPORT -----\")\n",
    "#         print(classification_report(y_te, y_pred))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "939c3b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression\n",
      "----- METRIC -----\n",
      "val accuracy 0.33970276008492567\n",
      "\n",
      "Model: RandomForestClassifier\n",
      "----- METRIC -----\n",
      "val accuracy 0.2760084925690021\n",
      "\n",
      "Model: DecisionTreeClassifier\n",
      "----- METRIC -----\n",
      "val accuracy 0.267515923566879\n",
      "\n",
      "Model: SGDClassifier\n",
      "----- METRIC -----\n",
      "val accuracy 0.2505307855626327\n",
      "\n",
      "Model: KNeighborsClassifier\n",
      "----- METRIC -----\n",
      "val accuracy 0.2653927813163482\n",
      "\n",
      "Model: MultinomialNB\n",
      "----- METRIC -----\n",
      "val accuracy 0.32908704883227174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_models(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576f5f81",
   "metadata": {},
   "source": [
    "### conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0311f8cb",
   "metadata": {},
   "source": [
    "- cleaning text did increase accuracy, though not by much\n",
    "- limiting vocabulary by removing frequent and occuring-once terms did not improve the results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haystack-venv",
   "language": "python",
   "name": "haystack-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
