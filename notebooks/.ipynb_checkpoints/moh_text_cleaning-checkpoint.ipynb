{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cf05789",
   "metadata": {},
   "source": [
    "## `1) Libraries`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "641fa9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de1ca9d",
   "metadata": {},
   "source": [
    "## `2) Getting Data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70e4e91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dbname': 'd1mikus7g5uss8',\n",
       " 'host': 'ec2-99-81-68-240.eu-west-1.compute.amazonaws.com',\n",
       " 'port': '5432',\n",
       " 'user': 'iohznziolcottb',\n",
       " 'password': '5a812ea29f6142328bc2afab03e48e6462939babe87610342cdf12e2d357a4f0',\n",
       " 'sslmode': 'require'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "creds = {'dbname': 'd1mikus7g5uss8',\n",
    " 'host': 'ec2-99-81-68-240.eu-west-1.compute.amazonaws.com',\n",
    " 'port': '5432',\n",
    " 'user': 'iohznziolcottb',\n",
    " 'password': '5a812ea29f6142328bc2afab03e48e6462939babe87610342cdf12e2d357a4f0',\n",
    " 'sslmode': 'require'}\n",
    "\n",
    "creds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d96c6852",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(host=creds['host'], database=creds['dbname'],\n",
    "                                user=creds['user'],\n",
    "                                password=creds['password'])\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0240b0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_Query = 'select q.description, q.question_id, a.answer_category_num, a.answer_justification, a.answer_upvote, \\\n",
    "              a.account_id_id from public.\"DiscH_prototype_question\" q RIGHT JOIN public.\"DiscH_prototype_answer\" a \\\n",
    "ON a.question_id_id=q.question_id'\n",
    "cur.execute(select_Query)\n",
    "QAs = cur.fetchall() \n",
    "QA_col = [\"question_description\", \"question_id\", \"answer_category_num\", \"answer_justification\", \"answer_upvote\", \"account_id\"]\n",
    "QA_df = pd.DataFrame(QAs, columns=QA_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c749363b",
   "metadata": {},
   "source": [
    "## `3) Preparation and Cleaning`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f73d9cd",
   "metadata": {},
   "source": [
    "### - Preparing DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f878791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# import the dediacritization tool\n",
    "from camel_tools.utils.dediac import dediac_ar\n",
    "\n",
    "# Reducing Orthographic Ambiguity\n",
    "from camel_tools.utils.normalize import normalize_alef_maksura_ar\n",
    "from camel_tools.utils.normalize import normalize_alef_ar\n",
    "from camel_tools.utils.normalize import normalize_teh_marbuta_ar\n",
    "\n",
    "# toknenization\n",
    "from camel_tools.tokenizers.word import simple_word_tokenize\n",
    "\n",
    "# Morphological Disambiguation (Maximum Likelihood Disambiguator)\n",
    "from camel_tools.disambig.mle import MLEDisambiguator\n",
    "mle = MLEDisambiguator.pretrained() # instantiation fo MLE disambiguator\n",
    "\n",
    "# tokenization / lemmatization (choosing approach that best fit the project)\n",
    "from camel_tools.tokenizers.morphological import MorphologicalTokenizer\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35c24f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(df):\n",
    "    df = df.copy().rename(columns={\"description\":'question_description'})\n",
    "    df  = df[[\"question_id\", 'question_description', 'answer_category_num']]\n",
    "    df.drop_duplicates(subset='question_description', inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # checking how many comments have different votes\n",
    "    for i, row in df.iterrows():\n",
    "\n",
    "        comment = row.question_description\n",
    "\n",
    "        # getting the dataframe for that comment\n",
    "        temp_df = df[df.question_description == comment]\n",
    "\n",
    "        # how many unique answers that comment has\n",
    "        n_ = temp_df.answer_category_num.nunique()\n",
    "\n",
    "        # changing the answer_category_num to the most frequent one\n",
    "        if n_ >= 2:\n",
    "            most_voted_label = temp_df.answer_category_num.value_counts().index[0]\n",
    "            df.at[i, 'answer_category_num'] = most_voted_label\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f08b5f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA_df_xlsx = pd.read_excel(\"../data/responses_data.xlsx\")\n",
    "# QA_df_xlsx = QA_df_xlsx.copy().rename(columns={\"description\":'question_description'})\n",
    "# QA_df_xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c40aa18b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>question_description</th>\n",
       "      <th>answer_category_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>وزير الخارجية اللبناني جبران باسيل قال في سلسل...</td>\n",
       "      <td>Religious affiliation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>سورية بلد الحضارات تربطها بعلية او بحيوان</td>\n",
       "      <td>Violent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4246</td>\n",
       "      <td>تقتلون وسام الحسن وتترحموعلية من أي أصناف المخ...</td>\n",
       "      <td>Racist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5304</td>\n",
       "      <td>معك خبر انو بلدة قطر متل ما سميتا مساحتها اكبر...</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1706</td>\n",
       "      <td>للامانه قوت الموسم اللي طاف كان هوا بس متحمس ح...</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3132</th>\n",
       "      <td>3720</td>\n",
       "      <td>كلامك هراء من دون اي قيمة تذكر انت بلوة من الب...</td>\n",
       "      <td>Violent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3133</th>\n",
       "      <td>7784</td>\n",
       "      <td>راح خبرك شو شايفة ب جبران باسيل</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3134</th>\n",
       "      <td>1318</td>\n",
       "      <td>كلمة جبران باسيل أخجلته وأخجلت كل الأمة العربية</td>\n",
       "      <td>Sexual harrasment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3135</th>\n",
       "      <td>3153</td>\n",
       "      <td>انا مش عم خوفك يا قراع انا عم قلك انقبر انقلع ...</td>\n",
       "      <td>Violent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3136</th>\n",
       "      <td>1786</td>\n",
       "      <td>إنت و حريمك عواهر</td>\n",
       "      <td>Sexual harrasment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3137 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      question_id                               question_description  \\\n",
       "0               1  وزير الخارجية اللبناني جبران باسيل قال في سلسل...   \n",
       "1               2          سورية بلد الحضارات تربطها بعلية او بحيوان   \n",
       "2            4246  تقتلون وسام الحسن وتترحموعلية من أي أصناف المخ...   \n",
       "3            5304  معك خبر انو بلدة قطر متل ما سميتا مساحتها اكبر...   \n",
       "4            1706  للامانه قوت الموسم اللي طاف كان هوا بس متحمس ح...   \n",
       "...           ...                                                ...   \n",
       "3132         3720  كلامك هراء من دون اي قيمة تذكر انت بلوة من الب...   \n",
       "3133         7784                    راح خبرك شو شايفة ب جبران باسيل   \n",
       "3134         1318    كلمة جبران باسيل أخجلته وأخجلت كل الأمة العربية   \n",
       "3135         3153  انا مش عم خوفك يا قراع انا عم قلك انقبر انقلع ...   \n",
       "3136         1786                                 إنت و حريمك عواهر    \n",
       "\n",
       "        answer_category_num  \n",
       "0     Religious affiliation  \n",
       "1                   Violent  \n",
       "2                    Racist  \n",
       "3                    Normal  \n",
       "4                    Normal  \n",
       "...                     ...  \n",
       "3132                Violent  \n",
       "3133                 Normal  \n",
       "3134      Sexual harrasment  \n",
       "3135                Violent  \n",
       "3136      Sexual harrasment  \n",
       "\n",
       "[3137 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA_df_clean = prepare_df(QA_df)\n",
    "QA_df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd92029a",
   "metadata": {},
   "source": [
    "### - Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5042d65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    return re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))',' ', text)\n",
    "\n",
    "def remove_html(text):\n",
    "    return BeautifulSoup(text, \"html.parser\").text\n",
    "\n",
    "symb_re = re.compile(r\"\"\"[!\"#$%&\\'()*+,-./:;<=>?@[\\\\\\]^_`{|}~،؟…«“\\\":\\\"…”]\"\"\")\n",
    "def remove_symbols(text: str) -> str:\n",
    "    return symb_re.sub(repl=\"\", string=text)\n",
    "\n",
    "multiple_space_re = re.compile(\"\\s{2,}\")\n",
    "def remove_multiple_whitespace(text):\n",
    "    return multiple_space_re.sub(repl=\" \", string=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f70e8d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_word_list = pd.read_csv('../Data/stop_words/list.csv')['words'].to_list()\n",
    "tokenizer = MorphologicalTokenizer(mle, scheme='atbtok', diac=False) # atbseg scheme \n",
    "def text_clean(txt):\n",
    "    txt = remove_urls(txt)\n",
    "    txt = remove_html(txt)\n",
    "    \n",
    "    # remove stopwords\n",
    "    txt = ' '.join(word for word in txt.split() if word not in stop_word_list)\n",
    "    \n",
    "    # dediacritization\n",
    "    txt = dediac_ar(txt)\n",
    "    \n",
    "    # normalization: Reduce Orthographic Ambiguity and Dialectal Variation\n",
    "    txt = normalize_alef_maksura_ar(txt)\n",
    "    txt = normalize_alef_ar(txt)\n",
    "    txt = normalize_teh_marbuta_ar(txt)\n",
    "    \n",
    "    # normalization: Reducing Morphological Variation\n",
    "    tokens = simple_word_tokenize(txt)\n",
    "    disambig = mle.disambiguate(tokens)\n",
    "    lemmas = [d.analyses[0].analysis['lex'] for d in disambig]\n",
    "    tokens = tokenizer.tokenize(lemmas)\n",
    "    txt = ' '.join(tokens)\n",
    "    \n",
    "    # remove longation\n",
    "    txt = re.sub(\"[إأآا]\", \"ا\", txt)\n",
    "    txt = re.sub(\"ى\", \"ي\", txt)\n",
    "    txt = re.sub(\"ؤ\", \"ء\", txt)\n",
    "    txt = re.sub(\"ئ\", \"ء\", txt)\n",
    "    txt = re.sub(\"ة\", \"ه\", txt)\n",
    "    txt = re.sub(\"گ\", \"ك\", txt)\n",
    "    \n",
    "    # remove non-arabic words, or non-numbers, or non-english words in the text\n",
    "    txt = re.sub(r'[^a-zA-Z\\s0-9\\u0600-\\u06ff\\u0750-\\u077f\\ufb50-\\ufbc1\\ufbd3-\\ufd3f\\ufd50-\\ufd8f\\ufd50-\\ufd8f\\ufe70-\\ufefc\\uFDF0-\\uFDFD.0-9]+'\n",
    "                 ,' ', txt)\n",
    "    \n",
    "    # remove symbols\n",
    "    txt = remove_symbols(txt)\n",
    "    \n",
    "    # remove multiple whitespace\n",
    "    txt = remove_multiple_whitespace(txt)\n",
    "    \n",
    "    \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5558bec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_df_clean['question_description_clean'] = QA_df_clean['question_description'].apply(text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "93042818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b9e677e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(QA_df_clean[\"question_description\"][i])\n",
    "# display(QA_df_clean[\"question_description_clean\"][i])\n",
    "# i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea2210e",
   "metadata": {},
   "source": [
    "### - removing frequent words, forming vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "19417d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b77662c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\modaj\\OneDrive\\Documents\\Personal\\Jobs\\SHAI\\intern - task 3\\haystack-venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "bag_of_words = count_vectorizer.fit_transform(QA_df_clean['question_description_clean'])\n",
    "feature_names = count_vectorizer.get_feature_names()\n",
    "word_frequencies = bag_of_words.toarray().sum(axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8c16602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary = count_vectorizer.vocabulary_\n",
    "# vocabulary_terms = list(vocabulary.keys())\n",
    "# terms_to_remove = []\n",
    "\n",
    "# for term in vocabulary_terms:\n",
    "#     frequency = vocabulary[term]\n",
    "#     print(\"term: {} / frequency: {}\".format(term, frequency))\n",
    "#     print()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "869db4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = count_vectorizer.get_feature_names()\n",
    "word_frequencies = bag_of_words.toarray().sum(axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e1cbca58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len vocab (before filtering): 7565\n",
      "len vocab (after filtering): 3209\n"
     ]
    }
   ],
   "source": [
    "word_occurence_set = list(zip(feature_names, word_frequencies))\n",
    "word_occurence_set_asc = sorted(word_occurence_set, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "vocabulary = []\n",
    "for wos in word_occurence_set_asc:\n",
    "    word, count = wos \n",
    "    \n",
    "    # frequently occuring words are filetered\n",
    "    if count > bag_of_words.shape[0] * 0.1:\n",
    "        continue\n",
    "    elif count == 1:\n",
    "        continue\n",
    "    else:\n",
    "        vocabulary.append(word)\n",
    "\n",
    "print('len vocab (before filtering): {}'.format(len(word_occurence_set_asc)))\n",
    "print('len vocab (after filtering): {}'.format(len(vocabulary)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b06cb60",
   "metadata": {},
   "source": [
    "### - TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7f5af893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "44fbdafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "50cf947d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = QA_df_clean[[\"question_description_clean\", \"answer_category_num\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a13ec459",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(QA_df_clean, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8d357971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>question_description</th>\n",
       "      <th>answer_category_num</th>\n",
       "      <th>question_description_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>4060</td>\n",
       "      <td>وانت صغيرة يجب تجاهلك واضح عندك عقد نفسية من ...</td>\n",
       "      <td>Violent</td>\n",
       "      <td>انت صغير و جب تجاهل واضح عند عقد نفس ي صغر</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>3347</td>\n",
       "      <td>مو سامعة بهنيبعل القرطاجي</td>\n",
       "      <td>Violent</td>\n",
       "      <td>مو سامع بهنيبعل قرطاجي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3132</th>\n",
       "      <td>3720</td>\n",
       "      <td>كلامك هراء من دون اي قيمة تذكر انت بلوة من الب...</td>\n",
       "      <td>Violent</td>\n",
       "      <td>كلام هراء قيمه ذكر بلا البلوات منتقل قتل قتيل ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>1027</td>\n",
       "      <td>وإنشاءالله ستبقى نور</td>\n",
       "      <td>Violent</td>\n",
       "      <td>وانشاءالله بقي نور</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2344</th>\n",
       "      <td>1480</td>\n",
       "      <td>يلعن قطر وحكام قطر لان من لعنهم لعن اسرائيل</td>\n",
       "      <td>Religious affiliation</td>\n",
       "      <td>لعن قطر حكم قطر لعن لعن اسراءيل</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      question_id                               question_description  \\\n",
       "501          4060   وانت صغيرة يجب تجاهلك واضح عندك عقد نفسية من ...   \n",
       "929          3347                          مو سامعة بهنيبعل القرطاجي   \n",
       "3132         3720  كلامك هراء من دون اي قيمة تذكر انت بلوة من الب...   \n",
       "942          1027                              وإنشاءالله ستبقى نور    \n",
       "2344         1480       يلعن قطر وحكام قطر لان من لعنهم لعن اسرائيل    \n",
       "\n",
       "        answer_category_num                         question_description_clean  \n",
       "501                 Violent         انت صغير و جب تجاهل واضح عند عقد نفس ي صغر  \n",
       "929                 Violent                             مو سامع بهنيبعل قرطاجي  \n",
       "3132                Violent  كلام هراء قيمه ذكر بلا البلوات منتقل قتل قتيل ...  \n",
       "942                 Violent                                 وانشاءالله بقي نور  \n",
       "2344  Religious affiliation                    لعن قطر حكم قطر لعن لعن اسراءيل  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "aeb415ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "?TfidfVectorizer(ngram_range=(1, 1), vocabulary=vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "16fd43e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 1), vocabulary=vocabulary)\n",
    "tfidf_tr = tfidf_vectorizer.fit_transform(train_data['question_description'])\n",
    "tfidf_val = tfidf_vectorizer.transform(test_data['question_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ee3e7559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definitions\n",
    "LogReg_model = LogisticRegression()\n",
    "RandomForestClassifier_model = RandomForestClassifier(max_depth=3, random_state=0)\n",
    "\n",
    "MultinomialNB_model = MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)\n",
    "SGDClassifier_model = SGDClassifier(class_weight='balanced', penalty='l1')\n",
    "KNeighborsClassifier_model = KNeighborsClassifier(n_neighbors=3)\n",
    "DecisionTreeClassifier_model = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "models = [LogReg_model, RandomForestClassifier_model, DecisionTreeClassifier_model,\n",
    "          SGDClassifier_model,   \n",
    "          KNeighborsClassifier_model,  MultinomialNB_model]\n",
    "model_names = ['LogisticRegression', 'RandomForestClassifier', 'DecisionTreeClassifier',\n",
    "               'SGDClassifier', 'KNeighborsClassifier', 'MultinomialNB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "424b5624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2666, 3209), (2666,))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = tfidf_tr, train_data['answer_category_num']\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d3e89f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((471, 3209), (471,))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test = tfidf_val, test_data['answer_category_num']\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f5d78cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(X_tr, X_te, y_tr, y_te):\n",
    "    for i, model in enumerate(models):\n",
    "        print(f\"Model: {model_names[i]}\")\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_te)\n",
    "        print('val accuracy %s' % accuracy_score(y_te, y_pred))\n",
    "#         print(classification_report(y_te, y_pred))  # for further evaluation\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "94f77890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression\n",
      "val accuracy 0.29723991507430997\n",
      "\n",
      "Model: RandomForestClassifier\n",
      "val accuracy 0.2951167728237792\n",
      "\n",
      "Model: DecisionTreeClassifier\n",
      "val accuracy 0.25902335456475584\n",
      "\n",
      "Model: SGDClassifier\n",
      "val accuracy 0.21656050955414013\n",
      "\n",
      "Model: KNeighborsClassifier\n",
      "val accuracy 0.26963906581740976\n",
      "\n",
      "Model: MultinomialNB\n",
      "val accuracy 0.2908704883227176\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_models(X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haystack-venv",
   "language": "python",
   "name": "haystack-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
